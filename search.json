[
  {
    "objectID": "oss/opensource.html",
    "href": "oss/opensource.html",
    "title": " Open Source",
    "section": "",
    "text": "My open source work has been focused on developer tools and infrastructure. I’ve contributed to projects such as fastai, Metaflow, Kubeflow, Jupyter, and Great Expectations, as well as many others. I list some of these below:"
  },
  {
    "objectID": "oss/opensource.html#fastai",
    "href": "oss/opensource.html#fastai",
    "title": " Open Source",
    "section": " fastai",
    "text": "fastai\nI maintain and contribute to a variety of fastai projects. Below are the projects I’ve been very involved in:\n\n\n\n\n\nProject\n\n\nDescription\n\n\nRole\n\n\nOther References\n\n\n\n\n\n\nfastpages \n\n\nAn easy to use blogging platform for Jupyter Notebooks. \n\n\nCreator\n\n\nBlog, Talk\n\n\n\n\nnbdev \n\n\nWrite, test, document, and distribute software packages and technical articles all in one place, your notebook. \n\n\nCore Contributor\n\n\nBlog, Talk\n\n\n\n\nfastcore \n\n\nA Python language extension for exploratory and literate programming. \n\n\nCore Contributor\n\n\nBlog\n\n\n\n\nghapi \n\n\nA Python client for the GitHub API \n\n\nCore Contributor\n\n\n Blog\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "oss/opensource.html#metaflow",
    "href": "oss/opensource.html#metaflow",
    "title": " Open Source",
    "section": " Metaflow",
    "text": "Metaflow\nI created notebook cards: A tool that allows you to use notebooks to generate reports, visualizations and diagnostics in Metaflow production workflows. Blog"
  },
  {
    "objectID": "oss/opensource.html#kubeflow",
    "href": "oss/opensource.html#kubeflow",
    "title": " Open Source",
    "section": " Kubeflow",
    "text": "Kubeflow\nI’ve worked on several projects related to Kubeflow, mainly around examples and documentation:\n\n\n\n\n\nProject\n\n\nDescription\n\n\nRole\n\n\nOther References\n\n\n\n\n\n\nGitHub Issue Summarization\n\n\nAn end-to-end example of using Kubeflow to summarize GitHub Issues. Became one of the most popular tutorials of Kubeflow. \n\n\nAuthor\n\n\nInterview with Jeremy Lewi\n\n\n\n\nkubeflow/codei-intelligence\n\n\nVarious tutorials and applied examples of Kubeflow. \n\n\nCore Contributor\n\n\nTalk\n\n\n\n\nThe Kubeflow Blog\n\n\nI used fastpages to create the official Kubeflow blog. \n\n\nCore Contributor\n\n\nSite\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "oss/opensource.html#jupyter",
    "href": "oss/opensource.html#jupyter",
    "title": " Open Source",
    "section": " Jupyter",
    "text": "Jupyter\nI created the Repo2Docker GitHub Action, which allows you to trigger repo2docker to build a Jupyter enabled Docker images from your GitHub repository. This Action allows you to pre-cache images for your own BinderHub cluster or for mybinder.org.\nThis project was accepted into the official JupyterHub GitHub org."
  },
  {
    "objectID": "oss/opensource.html#great-expectations",
    "href": "oss/opensource.html#great-expectations",
    "title": " Open Source",
    "section": " Great Expectations",
    "text": "Great Expectations\nI developed the Great Expectations GitHub Action that allows you to use Great Expectations in CI/CD Workflows. Blog."
  },
  {
    "objectID": "oss/opensource.html#other",
    "href": "oss/opensource.html#other",
    "title": " Open Source",
    "section": " Other",
    "text": "Other\nI worked as a staff machine learning engineer at GitHub from 2017 - 2022. I led or created the following open source projects that explored the intersection of machine learning, data and the developer workflow:\n\n\n\n\n\nProject\n\n\nDescription\n\n\nRole\n\n\nOther References\n\n\n\n\n\n\nCode Search Net \n\n\nDatasets, tools, and benchmarks for representation learning of code. This was a big part of the inspiration for GitHub’s eventual work on CoPilot. \n\n\nLead\n\n\n Blog, Paper\n\n\n\n\nMachine Learning Ops\n\n\nA collection of resources on how to facilitate Machine Learning Ops with GitHub. This project explored integrations with a wide variety of data science tools with GitHub Actions. \n\n\nCreator\n\n\nBlog\n\n\n\n\nIssue Label Bot\n\n\nA GitHub App powered by machine learning that auto-labels issues. \n\n\nCreator\n\n\nBlog, Talk\n\n\n\n\nCovid19-dashboard \n\n\nA demonstration of how to use GitHub Actions, Jupyter Notebooks and fastpages to create interactive dashboards that update daily.\n\n\n\nCreator\n\n\nNews Article\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#the-time-i-spend-with-kobo",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#the-time-i-spend-with-kobo",
    "title": "My little Dragon “kobo”",
    "section": "The time I spend with kobo",
    "text": "The time I spend with kobo\nI spend on average 8 hours on my laptop “kobo” doing a lot of programming, machine learning experiments and browsing many taps.\nI don’t use my phone a lot on average 1 or 2 hours, so i wake up and go to see my little friend and start journaling, wirte my ideas, perparing my todo list.\nI have been using it for 4 years now, and it was a nice period i love that it hasn’t broken till now, everything is working good even the battery can stand for the 2.5 hours in the battery life with a lot of memory and cpu usage\nYou can easily say that my laptop is now a part of me i can’t live without it any more my dairy, movies, work and college is depending on it"
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#who-is-kobo",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#who-is-kobo",
    "title": "My little Dragon “kobo”",
    "section": "Who is “Kobo”!",
    "text": "Who is “Kobo”!\n\n\n\nKobo\n\n\n\nSystem Specifications\nMy laptop is a Gfthin 95 core i7 9th gen, 16 GB RAM, 512GB SSD and GTX 1660 Ti, 120Hz screen"
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#msi-vs-lenovo",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#msi-vs-lenovo",
    "title": "My little Dragon “kobo”",
    "section": "MSI vs Lenovo",
    "text": "MSI vs Lenovo\n\nMSI with Linux\nAfter buying it, it wasn’t configured with Windows, but was another DOS version so I had to install a Windows version on it. After 1 week I get a lot of errors on it with the external monitor and the WiFi stops working or is not configured. I tried every Hindi video about this problem and gave it to specialists to try it, but in vain, the problem happened again and again.\nThe solution: It was my first year at a computer science college, so the geeky thing was to use Linux. After some search, I installed Ubuntu and then tried a lot of distros like Void Linux, but the one that I picked and still use is the amazing PopOS! which is based on Ubuntu but better than it!\nThe WiFi problem doesn’t appear again! And for Nvidia graphics, it’s solved in PopOS! which has a command to install some drivers. And everything works smoothly\n\n\nThe Cost of It!\nI bought it for the cost of 20,000 EGP, which at the time I bought it was $X, but now 20,000 EGP is worth $XX due to problems in my country.\nIts cost at that time is really high for my budget and family, but I insisted on buying it because I knew it would stay with me for years, so I wanted a good one.\n\n\nHow I Decided to Buy It!\nThe phrase “Machine learning needs an Nvidia GPU” was dancing in my mind, so my main focus was on a nice GPU card in a laptop with a low budget. After some search, I found that the best choices are MSI or Lenovo, but the Lenovo version cost about 4000 EGP more than the MSI.\n\nI tested the keyboard of the Lenovo, and every time I felt like I wanted to cut my fingers off\n\nIt wasn’t available online, so I had to travel 3 hours to the store that sells it. It was a nice experience to buy something I wanted instead of a random gift from my father."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#i-am-not-a-gamer",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#i-am-not-a-gamer",
    "title": "My little Dragon “kobo”",
    "section": "I Am Not a Gamer!",
    "text": "I Am Not a Gamer!\nI didn’t use it for gaming because I am not a gamer, but I used it heavily in programming and some machine learning and basic computer vision models, and it works so nicely!"
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#kobo-for-ml",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#kobo-for-ml",
    "title": "My little Dragon “kobo”",
    "section": "Kobo for ML",
    "text": "Kobo for ML\n Machine learning is a wide area, and you can use the GPU for 3 things:\n\nTrain a model from scratch\nFine-tune a model\nEvaluate a model (inference)\n\n\nTrain a model from scratch was an ideal task for such a GPU, but I was doing it for multiple computer vision classification tasks, learning new architectures, trying to build…etc. For ML you don’t always need a GPU but for deep learning, which is a subset of ML that uses more connected layers (which means more computing power and memory needs), you do.\nFine-tune a model is the case I used the most - I download a trained model and try to make it work better on my data. What you need here is enough GPU RAM - in my case it’s a 6GB card. This worked fine with computer vision algorithms and classic NLP models with less than 1 billion parameters. There’s no chance to try the LLAMAS models on such a card!\nEvaluate a model means to just load the model and not fine-tune it.\n\nI was fine with all the ML tasks I tried to do, unless I opened the door to large language models like the GPT family (ChatGPT for example). These models require a lot of memory and need a good graphics card like an RTX 30 or 40 series to test, and there’s no chance to train these models on any RTX card!\n\nWhy Not Just Use the Cloud!\nThere are two main solutions:\n\nKaggle\n\nKaggle has two GPU options, and I used it a lot, especially if the data was already hosted on Kaggle and was more than 10GB. Other than that, I downloaded a sample of the data and did my work on my own environment with CLI commands and VS Code configurations. This helped me a lot compared to just using the Kaggle editor, and it’s faster too! Sometimes the Kaggle kernel panics or just stops responding entirely!\n\nColab\n\nColab restarts after 4 hours and your work can get lost, and lots of annoying things like that happen a lot.\nYou have to pay for the GPU version. You get a number of hours to try it out, and it’s faster than my GTX 1660 by a good margin.\n\n\nBut I didn’t love these cloud solutions, and I found having my own local setup to be faster and more comfortable."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#kobo-for-web-development",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#kobo-for-web-development",
    "title": "My little Dragon “kobo”",
    "section": "Kobo for Web Development",
    "text": "Kobo for Web Development\nI sometimes work on web projects (Django and JavaScript frameworks, especially AstroJS). I never had any issues building and testing web projects - everything worked nicely and efficiently."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#the-battery-life",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#the-battery-life",
    "title": "My little Dragon “kobo”",
    "section": "The Battery Life",
    "text": "The Battery Life\nThe battery life can keep it working for 2.5 hours when the power is out if you switch to battery saver mode. I don’t think it could last more than 1 hour in normal mode! This is the laptop’s biggest issue. Sometimes it powers off even when fully charged if you do a lot of computation without plugging it in."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#the-heat",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#the-heat",
    "title": "My little Dragon “kobo”",
    "section": "The Heat",
    "text": "The Heat\n I didn’t find heat to be a problem or even the fan noise in most of my work. But sometimes when running a deep learning model, the fan noise is a bit loud and it does get really hot. For normal coding and browsing though, there are no issues and the cooling system is fast. Overall I didn’t find heat to be a major problem."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#the-keyboard",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#the-keyboard",
    "title": "My little Dragon “kobo”",
    "section": "The Keyboard",
    "text": "The Keyboard\nThe keyboard is very responsive and well configured with smooth clicks - no issues or sticky keys even though I have fat fingers!\nI’ve been using this machine for 4 years and I write a lot. No broken keys have happened despite my clumsy fingers. I have a mechanical keyboard that I sometimes use, but I always miss the feel of the built-in keyboard. The red backlight is decent."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#finally",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#finally",
    "title": "My little Dragon “kobo”",
    "section": "Finally!",
    "text": "Finally!\n I just wanted to say that I love “Kobo” and I’ve spent nice times with it - some really difficult and others really happy. It’s been a loyal friend and something to rely on."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "",
    "text": "#defintion MTEB: MTEB spans 8 embedding tasks covering a total of 58 datasets and 112 languages. Through the benchmarking of 33 models on MTEB."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#introduction",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#introduction",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "",
    "text": "#defintion MTEB: MTEB spans 8 embedding tasks covering a total of 58 datasets and 112 languages. Through the benchmarking of 33 models on MTEB."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#embedding-models",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#embedding-models",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "Embedding models",
    "text": "Embedding models\n\nText embedding models like GLove lack context awareness and ar=e thus commonly labeled as word embedding model. They consist of a layer mapping each input word to a vector often followed by an averaging layer to provide a final embedding invariant of input length.\nTransformers inject context awareness into language models via self-attention and form the foundation of most recent embedding models.\n\nBERT uses the transformer architecture and performs large-scale self-supervised pre-training. The resulting model can directly be used to produce text embeddings via an averaging operation alike Glove.\nSBERT be beneficial to perform additional fine-tuning of the transformer for competitive embedding performance.\nMost recent fine-tuned embedding models use a contrastive loss objective to perform supervised fine-tuned on positive and negative text pairs\n#critique Due to the large variety of available pretrained transformers,there is an at least equally large variety of potential text embedding models to be explored.This leads to confusion about which model provides practitioners with the best performance for their embedding use case."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-problem",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-problem",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "The problem",
    "text": "The problem\n\nThe problem with the current evaluation regime of current text embedding models rarely covers the breadth of their possible use cases.\n\n#example SimCSE or SBERT solely evaluate on STS and classification tasks,leaving open questions about the transfer ability of the embedding models to search or clustering tasks.\n\nevaluating embedding methods on many tasks requires implementing multiple evaluation pipelines.\nimplementation details like preprocessing or hyperparameters may influence the results making it unclear whether performance improvements simply come from a favorable evaluation pipeline. This leads to the “blind” application of these models to new use cases in industry or requires incremental work to reevaluate them on different tasks."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-solution-with-this-benchmark",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-solution-with-this-benchmark",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "The solution with this benchmark",
    "text": "The solution with this benchmark\n\nMTEB consists of 58 datasets covering 112 languages from 8 embedding tasks:\n\n\nBitext mining\nclassification\nclustering\npair classification\nreranking, retrieval\nSTS\nsummarization.\n\n\nMTEB software is available open-source1 enabling evaluation of any embedding model by adding less than 10 lines of code.\nDatasets and the MTEB leaderboard are available on the Hugging Face Hub2 .\nWe evaluate over 30 models on MTEB with additional speed and memory benchmarking to provide a holistic view of the state of text embedding models. We cover both models available open-source as well as models accessible via APIs, such as the OpenAI Embeddings endpoint\nIt aims to sheds light on the weaknesses and strenghts of individual models,such as SimCSE’s(Gao et al., 2021b) low performance on clustering and retrieval despite its strong performance on STS."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-mteb-desiderata",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-mteb-desiderata",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "The MTEB Desiderata",
    "text": "The MTEB Desiderata\nMETB is build on a set of desiderat.\n\nDiversity:\n\nit consists of 58 total datasets, 10 are multilingual, covering 112 different langauges.\nSentence-level and paragraph level datasets are included to contrast performance on short and long texts.\n\nSimplicity\n\nIt provides a simple API for plugging in any model that given a list of text can produce a vector for each list of texts can produce a vector for each list item with a consistent shape.\n\nExtensibility\n\nyou can add new datasets for existing tasks via a single file that specifies the task and a Huggingface dataset name where the data has been uploaded.\nNew tasks require implementing a task interface for loading the data and an evaluator for benchmarking\n\nReproduciblity\n\nThrough versioning at a dataset and software level,they make it easy to reproduce results in METP.\nJSON files corresponding to all results available in this paper have been made available together with the MTEB benchmark"
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#tasks-and-evaluation",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#tasks-and-evaluation",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "Tasks and Evaluation",
    "text": "Tasks and Evaluation\n#definition Bitext Mining\nInputs are two sets of sentences from two different languages. For each sentence in the first set, the best match in the second set needs to be found.\n\nThe matches are commonly translations.\nThe Provided model i used to embed each sentence and the closest pairs are found via cosine similarity\nF1 serves as the main metric for bitext mining.Accuracy, precision and recall are also computed. #definition Classification\nA train and test set are embedded with the provided model.\nThe train set embeddings are used to train a logistic regression classifier with 100 maximum iterations, which is scored on the test set.\nThe main metric is accuracy with average precision and f1 additionally provided. #definition Clustering Given a set of sentences or paragraphs, the goal is to group them into meaningful clusters.\nA mini-batch k-means model with batch size 32 and k equal to the number of different labels is trained on the embedded texts.\nThe model scored using V-measure - V-measure does not depend on the cluster label,thus the permutation of labels does not affect the score. #definition Classification A pair of text inputs is provided and a label needs to be assigned. Labels are typically binary variables denoting duplicate or paraphrase pairs.\nThe two texts are embedded and their distance is computed with various metrics (cosine similarity, dot product, euclidean distance, manhattan distance).\nUsing the best binary thresh- old accuracy, average precision, f1, precision and recall are computed.\nThe average precision score based on cosine similarity is the main metric. #definition Reranking : Inputs are a query and a list of relevant and irrelevant reference texts. The aim is to rank the results according to their relevance to the query.\nThe model is used to embed the references which are then compared to the query using cosine similarity.\nThe resulting ranking is scored for each query and averaged across all queries.\nMetrics are mean MRR@k and MAP with the latter being the main metric. #definition Retrieval Each dataset consists of a corpus, queries and a mapping for each query to relevant documents from the corpus.\nThe aim is to find these relevant documents.\nThe provided model is used to embed all queries and all corpus documents and similarity scores are computed using cosine similarity. After ranking the corpus documents for each query based on the scores, nDCG@k, MRR@k, MAP@k, precision@k and recall@k are computed for several values of k. nDCG@10 serves as the main metric.\nMTEB reuses datasets and evaluation from BEIR (Thakur et al., 2021). #definition Semantic Textual Similarity (STS) Given a sentence pair the aim is to determine their similarity. Labels are continuous scores with higher numbers indicating more similar sentences.\nThe provided model is used to embed the sentences and their similarity is computed using various distance metrics.\nDistances are benchmarked with ground truth similarities using Pearson and Spearman correlations.\nSpearman correlation based on cosine similarity serves as the main metric (Reimers et al.,2016). #definition Summarization A set of human-written and machine-generated summaries are provided. The aim is to score the machine summaries. The provided model is first used to embed all summaries. For each machine summary embedding, distances to all human summary embeddings are computed. The closest score (e.g. highest cosine similarity) is kept and used as the model’s score of a single machine-generated summary. Pearson and Spearman correlations with ground truth human assessments of the machine-generated summaries are computed. Like for STS, Spearman correlation based on cosine similarity serves as the main metric\n\n\n#sidenote Non-Transformers : LASER (Heffernan et al.,2022) is the only context aware non-transformer model we benchmark, relying on an LSTM (Hochreiter and Schmidhuber, 1997) instead. Similar to LaBSE, the model trains on parallel data and focuses on bitext mining applications. ![[Pasted image 20231028124555.png]]"
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#analysis",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#analysis",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "Analysis",
    "text": "Analysis\n\nwe observe that there is considerable variability between tasks. No model claims the state-of-the-art in all seven English tasks.\nThere is even more variability in the results per dataset present in the appendix.\nFurther, there remains a large gap between self-supervised and supervised methods.\nSelf-supervised large language models have been able to close this gap in many natural language generation tasks (Chowd- hery et al., 2022).\nHowever, they appear to still require supervised fine-tuning for competitive em- bedding performance.\nWe find that performance strongly coorelates with model size, A majority of MTEB tasks are domainted by multi-billion parameter models.However, these come at a significant cost\nFor classification\n\nST5 models dominate the classification task across most datasets\nST5-XXL has the highest average performance, 3% ahead of the best non-ST5 model, OpenAI Ada Similarity\n\nClustering\n\nDespite being almost 50x smaller, the MPNet embedding model is on par with the ST5- XXL state-of-the-art on Clustering. This may be due to the large variety of datasets MPNet (and MiniLM) has been fine-tuned on.\nClustering requires coherent distances between a large number of embeddings.\nModels like SimCSE-sup or SGPTnli, which are only fine-tuned on a single dataset,NLI, may produce incoherent embeddings when encountering topics unseen during fine-tuning.\nRelatedly, we find that the query embeddings of SGPT-msmarco and the Ada Search endpoint are competitive with SGPT-nli and the Ada Similarity endpoint,respectively.\nWe refer to the public leaderboard5 for Ada Search results. This could be due to the MSMARCO dataset being significantly larger than NLI.\nThus, while the OpenAI docs recommend using the similarity embeddings for clustering use cases6 , the retrieval query embeddings may be the better choice in some cases.\n\nPair Classification\n\nGTR-XL and GTR-XXL have the strongest performance. Pair classification is closest to STS in its framing, yet models rank significantly differently on the two tasks. This highlights the importance of benchmarking on a diverse set of tasks to avoid blindly reusing a model for a different task.\n\nReranking\n\nMPNet and MiniLM models perform strongly on reranking tasks.\nOn SciDocsRR (Co-han et al., 2020a) they perform far better than big- ger models, which is likely due to parts of SciDocsRR being included in their training data.\nOur scale of experiments and that of model pre-training make controlling for data contamination challenging.\nThus, we ignore overlap of MTEB datasets with model training datasets in MTEB scores.\nAs long as enough datasets are averaged, we believe these effects to be insignificant.\n\nRetrieval\n\nSGPT-5.8B-msmarco is the best em- bedding model on the BEIR subset in MTEB as well as on the full BEIR benchmark (Thakur et al., 2021; Muennighoff, 2022).\nThe even larger 7.1B SGPT model making use of BLOOM (Scao et al., 2022) performs significantly weaker, which is likely due to the multilinguality of BLOOM.\nModels geared towards STS (SimCSE, ST5, SGPT- nli) perform badly on retrieval tasks.\nRetrieval tasks are unique in that there are two distinct types of texts: Queries and documents (“asymmetric”), while other tasks only have a single type of text (“symmetric”).\nOn the QuoraRetrieval dataset, which has been shown to be largely symmetric (Muennighoff, 2022), the playing field is more even with SGPT-5.8B-nli outperforming SGPT- 5.8B-msmarco,\n\nSTS & Summarization\n\nRetrieval models (GTR, SGPT-msmarco) perform badly on STS, while ST5-XXL has the highest performance.\nThis highlights the bifurcation of the field into separate embedding models for retrieval (asymmetric) and similarity (symmetric) use cases (Muennighoff, 2022)."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#efficiency",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#efficiency",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "Efficiency",
    "text": "Efficiency\nMaximum speed -&gt; Word Embedding models offer maximum speed with Glove taking the lead on both performance and speed, thus making the choice simple in this case\nMaximum performance -&gt; If latency is less important than performance Depending on the task at hand, GTR-XXL, ST5-XXL or SGPT-5.8B may be the right choice,\nSpeed and Peformance -&gt; The fine-tuned MPNet and MiniLM models lead the middle cluster making the choice easy.\n\n#todo you can check the gte architecture here it’s highly related to the MTEP [[tiny-gte_transformer_model]]"
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#conclusion",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#conclusion",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "Conclusion",
    "text": "Conclusion\n\nWe found model performance on different tasks to vary strongly with no model claiming state-of-the-art on all tasks.\nOur studies on scaling behavior, model efficiency and multilinguality revealed various intricacies of models that should ease the decision-making process for future research or industry applications of text embeddings.\n\n\nThanks for reading. If you have any questions, feel free to comment down below or reach out to me on twitter @AbdelkareemElk1."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#references",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#references",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "References",
    "text": "References\n\nhttps://huggingface.co/blog/mteb\nhttps://arxiv.org/abs/2210.07316"
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html",
    "href": "blog/posts/life_style/fake_graviety.html",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "",
    "text": "target\n\n\nأحد الممارسات التي أقوم بها في بعض الأحيان هي مراقبة مصادر الأفكار التي تأتيني والمحفزات لها وتتبع أثر تلك الأفكار علي أفعالي ومشاعري ، يعتبرها البعض تفكير زائد وأعتبرها أنا نعمة تنقذني أحيانا من الإستغراف في الكثير من المهام والإستيقاظ متاخرا نسبيا.\nبدأت المشكلة في الظهور في السنة الأولي الجامعية في تلك البداية التي يحاول كل شخص أن يظهر مهاراته وقدراته ويثبت نفسه ويحاول إثارة إعجاب الأخرين وتنشاءة العلاقات مع أناس من كافة المحافظات ذلك الدخول المفاجئ والكثيف كان له أثر نفسي سئ.\nمثل تغير الاهتمامات علي المستوي الشخص والمعرفي و الدخول في تلك العلاقات الكثيره بدأت الأهداف المركزية التي كنت أحلم بها و أفكاري ومبادئ بالتشتت والتأثر بجاذبية كل شخص تعرفت عليه وصار بيني وبينه علاقة زمالة بل وحتي مجرد رؤية صفحته علي وسائل التواصل كل هذا طبيعي و مفهوم.\nبعد محاول مراقبة الوقت اليومي واين يتم استنافزه وأين تسنزف أفكاري و مخزون التركيز لدي وجدت أني أذهب لنشر بيت الشعر هذا وتليخص الكتاب ذاك لأنتظر رد فعل فلان وعلان و انغماسي في الردود علي منشوراتهم وتتبع أخبارهم و تضخم طفيليي الفضول عندي بشكل مبالغ فيه مما أصبح يسبب قلق وحيرة وتشتت ومقارانات و وضياع أعمار."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#البداية",
    "href": "blog/posts/life_style/fake_graviety.html#البداية",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "",
    "text": "target\n\n\nأحد الممارسات التي أقوم بها في بعض الأحيان هي مراقبة مصادر الأفكار التي تأتيني والمحفزات لها وتتبع أثر تلك الأفكار علي أفعالي ومشاعري ، يعتبرها البعض تفكير زائد وأعتبرها أنا نعمة تنقذني أحيانا من الإستغراف في الكثير من المهام والإستيقاظ متاخرا نسبيا.\nبدأت المشكلة في الظهور في السنة الأولي الجامعية في تلك البداية التي يحاول كل شخص أن يظهر مهاراته وقدراته ويثبت نفسه ويحاول إثارة إعجاب الأخرين وتنشاءة العلاقات مع أناس من كافة المحافظات ذلك الدخول المفاجئ والكثيف كان له أثر نفسي سئ.\nمثل تغير الاهتمامات علي المستوي الشخص والمعرفي و الدخول في تلك العلاقات الكثيره بدأت الأهداف المركزية التي كنت أحلم بها و أفكاري ومبادئ بالتشتت والتأثر بجاذبية كل شخص تعرفت عليه وصار بيني وبينه علاقة زمالة بل وحتي مجرد رؤية صفحته علي وسائل التواصل كل هذا طبيعي و مفهوم.\nبعد محاول مراقبة الوقت اليومي واين يتم استنافزه وأين تسنزف أفكاري و مخزون التركيز لدي وجدت أني أذهب لنشر بيت الشعر هذا وتليخص الكتاب ذاك لأنتظر رد فعل فلان وعلان و انغماسي في الردود علي منشوراتهم وتتبع أخبارهم و تضخم طفيليي الفضول عندي بشكل مبالغ فيه مما أصبح يسبب قلق وحيرة وتشتت ومقارانات و وضياع أعمار."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#الإنبهار",
    "href": "blog/posts/life_style/fake_graviety.html#الإنبهار",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "الإنبهار",
    "text": "الإنبهار\n\n\n\ntarget\n\n\nالإنبهار السريع باي شخص يتحدث عن شئ لا أعرفه مرت 6 شهور تقريبا وأنا متاثر ببعض الأشخاص الذين كنت أعتقد ان لديهم قدر من العلم والصدق والاشتراك في كورساتهم التي ستجعلني مبرمج لأحصل علي دخل بالدولار في نهاية الشهر القادم ذلك الشهر الذي أمتد 4 سنوات دراسية !!! شهر أسبوعه بمقدار عام!\nلنرمز لتلك الفئة من المؤثرين بالرمز س وهو إختصار لكلمة سبوبة ينتشر هولاء الأشخاص في أماكن صيد المبتدائين يبيع لك هولاء الأشخاص الوعود البراقة كورس لتعلم السايبر سيكورتي في خلال 3 شهور أو تعلم دبلومة علم البيانات والذكاء الاصطناعي في شهرين تنبهر كثيرا بالكارزيما وطريقة الالقاء ونظافة المكان والمحتوي الذي يعد مبهر بالنسبة لك فلبس لديك أي آليات للحكم علي الشخص أو المحتوي فكل معرفتك في العلم هي تعال نجرب حصة عند أستاذ شكري\nطالب لا حول له ولا قوة لا يعرف أي شئ في عقلة غير ملخص الدرس الذي يحفظة عن ظهر قلب ويذهب للامتحان ليسكب تلك الاسئلة الجاهزه في ورقة الامتحان الابله ليتفاجئ ذلك المسكين أن لا يوجد تعليم جامعي حقيقي وانها كانت كذبة العمر الضائع في كل تلك السنوات من الابتدائية وهو يسأل متي الراحة من هذا التلقين الفاشل وتكون الاجابة الكلاشكية هي أتعب الوقتي علشان تستريح بعدين بعدين امته!\nفي الجامعة عندما تنتهي من ال3 الثانوي لتصير دكتور مخ وأعصاب أو مهندس بترول"
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#الكهنة-و-المعبد",
    "href": "blog/posts/life_style/fake_graviety.html#الكهنة-و-المعبد",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "الكهنة و المعبد",
    "text": "الكهنة و المعبد\nسواء كانت نتيجة الثانوية مرضية و أرضيت والديك أم محزنة وأصابك اكتائب وامتلئت بالحزن فلا تبتأس فالقادم أسوء عليكما ومرحبا بك في عصر الكهنة الجامعية بعد مرات البحث العديدة وسماع الأراء هنا وهناك والكثير من الفيدوهات التي تذكر لك مميزات الجامعة الفلانية وأقسامها ونعيمها وتذكرك بالابتعاد عن الهندسة والجامعات التقليدية والذهاب الي كليات الجديدة مثل:\n\nكلية الملاحة والفضاء\nكلية الثروة السمكية\nوالحبيبة الخبيثة كلية الذكاء الاصطناعي كلية المستقبل وصناعة الريموتات ومكن الخياطة\nوالكثير من الكليات الجديدة أو القسام ذات الأسماء البراقة “ليس عندي أي إعتراض عن أي كلية أو تخصص بل أتمني أن يكون عندي عمر لكل تخصص فشرف العلم كافي”\n\nلكن المشكلة في أنها مسرحية وسبوبة عامة وكل فرد مشارك فيها بداية من المدرسين والأهل و المهاطيل الجامعيين\nذلك المعبد الملئ بالالهة والكهنة والمحرمات والذي بمجرد دخولك لبوابة ذلك المعبد وتقديمك لأوراق الالتحاق فقد تمت عليك اللعنة الأبدية وكما دخلت جسد ممتلئ بالأمل أو حتي جسد ممتلئ بالحزن والندم فسرعا ما ستخرج جثة هامدة فاقدة الرغبة علي العيش بل تفقد في كثير من المرات إنسانتيك"
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#هيكلية-المعبد",
    "href": "blog/posts/life_style/fake_graviety.html#هيكلية-المعبد",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "هيكلية المعبد",
    "text": "هيكلية المعبد\nبعدما قدرت علي النجاة ولحاق أي وسيلة مواصلات سواء من بيتك للجامعة أو للموقف العام او من موقف العام للجامعة هنيائا لك فقد استنفزت 20% من قدرتك علي الصمود\nستدخل هذا الصرح الهائل المبهر في بدايته وتتوجه الي المعبد الذي لعنت به الكثير من الخدم الأكبر منك يتنصلون للبحث عن الفتيات الساذجات لإشباع شهواتهم."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#الطاقة-السوداء",
    "href": "blog/posts/life_style/fake_graviety.html#الطاقة-السوداء",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "الطاقة السوداء",
    "text": "الطاقة السوداء\nكان التفسير الوحيد لكل هذا العبث هو وجود خطة شر كبري من الفراعنة القدماء لتوليد أكبر قدر من الطاقة السلبية والإحباط في كل مكان يجتمع فيه البشر او كان يفترض ان يكون ولادة جديدة لأرواح متعبة.\nيتم إستخدام تلك الطاقة وإمتصاصها فهي تعني لهم الخلود فتلك المنطقة حلت عليها لعنة لا يمكن حلها إلا بالقضاء علي الفراعنة و إعادة الارواح التي أغتصبت والأحلام المفقودة أحلام البسطاء وللحديث هنا بقية في مكان وزمان أخري."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#الجاذبية",
    "href": "blog/posts/life_style/fake_graviety.html#الجاذبية",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "الجاذبية",
    "text": "الجاذبية\n\n\n\ntarget\n\n\nالجاذبية (من فعل جَذَبَ) وتعرف أيضاً باسم الثَقالة (من فعل ثَقُلَ) هي ظاهرة طبيعية يتم بواسطتها تحريك وانجذاب كل الأشياء من الكتلة أو الطاقة -بما في ذلك الكواكب والنجوم والمجرات وحتى الضوء- نحو بعضها البعض.\nعلى الأرض، تعطي الجاذبية ثقلاً للأجسام المادية (الوزن)، وجاذبية القمر تسبب المد والجزر في المحيط. تسبب الانجذاب الجاذبي للمادة الغازية الأصلية الموجودة في الكون في البدء في الاندماج النووي، وتكوين النجوم -وتجميع النجوم معًا في مجرات- لذا فإن الجاذبية مسؤولة عن العديد من الهياكل الواسعة النطاق في الكون.\nعلى الرغم من ذلك فإن آثار الجاذبية تصبح أضعف بشكل متزايد على الأشياء البعيدة."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#جاذبية-الأشياء",
    "href": "blog/posts/life_style/fake_graviety.html#جاذبية-الأشياء",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "جاذبية الأشياء",
    "text": "جاذبية الأشياء\nهل يمكنك أن تفكر كثيرا في كافة الأشياء التي تجذبك لها من حولك علي مستوي الوقت و الأفكار والمشاعر وقوة الإرادة!\n\nتاثير أصدقائك عليك\nمكان سكنك\nأسرتك\nوسائل التواصل\n\nالتركيز ليس هو قضاء أكثر وقت في أمر ما لكنه قدرتك علي إبعاد المشتات عن تلك المهمة والقدرة علي التركيز الكامل فيها. فمثلا: فمثلا التركيز هو ان تذاكر 4 ساعات برمجة فقط وليس ان تركز علي ساعتين برمجة ويب وساعة ماركتنيج وساعة مذاكرة للجامعة ومحاول التنقل بينهم علي= مدار اليوم او كما احب ان اقول علي مدار نوم!\n\nليست القضية كم لدي من الوقت لأعمل كذا بل كم من هذا الوقت لدي القدرة علي عمل هذا فوجود 10 ساعات فراغ ليس معناه انك تستطيع إستخدامهم جميعا بل يوجد منهم مثلا 4 ساعات فقط وهذه رحلة طويلة وتحتاج لتنظيم عالي ومحاول وخطاء والكثير من النصائح ليس هذا وقت ذكرها.\nفلهذا ينصح بالابتعاد عن وسائل التواصل و تدفق المعلومات التي تشغل عقلك وقلبك في بداية اليوم فبعد ساعتين تشعر بالصداع والرغبة علي النوم وكأن عقلك توقف عن العمل."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#حديث-تخرج",
    "href": "blog/posts/life_style/fake_graviety.html#حديث-تخرج",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "حديث تخرج",
    "text": "حديث تخرج\n مدي علي تخرجي من الجامعة بتقدير جيد جدا +B مترفع بضعة أيام تتملكني فرحة عارمة أنني قدت هربت من هذه السجون التي وضعت عليا طوالة هذه الأعوام شعور مريح جدا تبقي سجن الخدمة العسكرية اللهم إني أسالك الإعفاء من هذه التجربة ومن شرها وشر من فيها.\nحديث تخرج في مدار جاذبية الأشياء السؤال الذي لم يتم تحديده بالكامل هو فيما سوف أتخصص الآن أفكر في إجابة منذ 3 سنوات وكل شهرين تزداد معرفتي وخبرتي وأجد أنني ليس لدي إجابة حقيقة حتي الآن. هناك 3 تخصصات أستطيع ان أبدا بها:\n\nمهندس برمجيات (ومن خلاله أختار فرع مثل برمجة الواجهات او الباك إند)\nمتخصص في علوم البيانات ( من خلاله أختار فرع مثل تعلم العميق والمجالات البحثية الشيقة الأخري)\nالماركتينج + السيو + كتابة المحتوي (من خلال هو أقرب فرصة للحصول علي المال لسبب غير معلوم لن أصرح عنه) أين هي الصعوبة! الصعوبة تكمن في جاذبية كل فرع من تلك الفروع و أثر أختيار أحدهم عن الأخر من ناحية الأيجابيات والسلبيات لكلا منهما وليس هذا مكان النقاش ولكن ما أريد أن أشير له هو تأثير الإختيارات عليك و أثرها علي حياتك و وماهي أسباب ميولك الحقيقة لإختيار محدد.\n\nكيف سأختار الآن في الحقيقة قد أخرت ان أحجم جذب كل تخصص منهم لي في الفترة الحالية بالقدر الذي أرسمه لنفسي ومحاول الإلتزام بذلك والجمع بينهم للخروج بأفضل إستفادة ممكنة."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#جاذبية-المشاعر-الذاتية",
    "href": "blog/posts/life_style/fake_graviety.html#جاذبية-المشاعر-الذاتية",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "جاذبية المشاعر الذاتية",
    "text": "جاذبية المشاعر الذاتية\n\n\n\ntarget\n\n\nبعض الأمثلة التي أتذكرها و أجد فيها إستغراق أصحابها في كثير من الأوقات بغير قصد ونكران شديد لما يفعلون وهذا ما أخاف و أحاذر منه.\n\nالجيم\nفي صباح اليوم دخل شخص أول مره أراه في الجيم يبدو متمرس في كمال الأجسام له نفسي عمري تقريبا يمشي مثل الحصان بشكل مريب تشعر كأن يريد أن يخبط في أي شئ أمامه ولديه إبتسامة عريضه طوال الوقت وعينيه تنظر لكل من حوله بشكل مريب وكأنه تقول هل تراني! أو هو كذا قرائها عقلي طوال الساعتين التي قضاهم بجانبي يصرخ بصوت عالي أعلي من روني كولمان بشكل مريب برغم أن الاثقال التي يتمرن بها قريبة جدا وأحيانا أقل من التي أتمرن بها و تعامله مع الأوزان غريب بحق يرفع البار الحديدي لأعلي ويسقطه علي الأرض بقوه ولديه هوس بالصراخ والتكسير حتي أن من يبعده دورين يستيطع سماعة ومن يسكن في الدور او يمشي في الشارع ونحن في الدور ال3 يستطيع سماعة بصوت واضح فياتري ماهو مصدر الجاذبية والمحرك لهذه الأفعال التي لم تستطيع كلماتي وصف الهمجية و الإزعاج المبتذل اليوم\n\n\nالجامعة\nيحضرني ذكر مثالين منتشرين طالب الإتحاد او الأنشطة الطالبية الكثيره\n\nإتحاد الطلبة والأنشطة الطلابية\nذلك الطلاب صاحب البدلة الأنيقة والإبتسامة العريضة الذي يشغل نفسه في الإحتفالات والتنظيمات والممارسات الإجتماعية الكثير وتنظيم الندوات والكثير من هذا النفاق (أتحدث عن الواقع الجامعي لعام 2024) الأمر يشبه مسرحية سخيفة يصبح فيها هذا الطالب البائس يرقص علي هذا المسرح المزيف ويظن أنه بطل الفيلم وسوف ينتصر في النهاية ولكن كل المعتطيات تصرح بأنه مهرج بإمتياز ويخادع نفسه.\n\n\nأذكي شخص في عالمه\n\n\n\ntarget\n\n\nذلك الزميل الذي تجدة يحاول بإستمرار أن يثبت لك أنه أذكي منك وأذكي من أي أحد في الغرفة وعلي بعد 100 كيلو متر من مركز وقوفه.\nذلك الزميل ينعمس في صوت الأيجو الذي بداخله فتجده ينعرف عن البوصلة الصحيحه لتحصيل العلم بشكل رأسي وأفقي بتوازن حقيقي ليصل الي مرحلة من إتقان العلم و الحصول علي وظيفة مريحة كم أشعر بالحزن عليه فلديه الكثير من الطاقة ولكنه يستغلها بشكل ربما يكون خاطئ و مؤكد أنه مزعج أيضا!\nالمؤسف انه بعد مرور بعد الوقت يبدا كل شخص منا في جمع معلومات في التخصص الذي يعجبه والإلتحاق بوظائف وصديقنا لا يزال في سراب أذكي شخص في العالم ومحاولاته المستمره بدون قصد لتبيان ذلك أصبحت مزعجة وأصبحت معرفته التي أكثرها أفقية مصدر إزعاج ونوع من أنواع التباهي المثير للشفقة والغضب أحيانا! يمكن التفكير في جاذبية الإيجو عليك وخداعك لنفسك في الحاليتن والتفصيل كثير وليس الغرض التعميم.\nمقترحات للخروج من هذا الفخ\n\nراقب وقتك علي وسائل التواصل الأجتماعي وليس المقصد كم تجلس علي هذه المنصات ولكن أنظر الي تعلقياتك و منشوراتك ستجد أن أكثر شخص تتحدث عنه بشكل صريح أو خفي هو كم أنت عبقري وتفهم ما لايفهمه الأخرين! كم أنت ذكي! ستجدك متقوقع علي ذاتك!\nالإنسحاب من مراقبة و أعين الناس و محاسبة النفس بشكل أكثر حزم و الأنسحاب هنا مقصود به وسائل التواصل و التجمعات التي تظهر فيه تلك الأفعال مثل مذاكرتك في نفس غرفة السكن الجامعي أمام أصدقائك و سؤالك المستمر للأخرين هل تعرف ماهي نظرية الهتوانا مطاطا ! و دعني أشرح لك كم صعوبة هذه النظرية وعبقريتها ..الخ\nلا تترك إشارات للاخرين مثل الاهتمام الزائد بحالات الواتس والتيليجرام وإظهار المستمر لماذا تفعل مثل ديسكورد والأغاني التي تستمع لها\n\n\n\n\nهوس الجمال\nهوس الجمال تلك الفتاة التي كل إهتمامها هو جمالها والجمال والثروة والمال تجد أنه مهوسة بالجانب البصري عندها بشكل يجعلك تظنها ماكيت مخيف من الإنجذاب للماديات بشكل يطغي علي جمالها كأنثي يصل الأمر الي إلغاء الهالة المحيطة بها كأم أو زوجة أو فتاة عموما تشعر.\nمشاهدة الإستغرام والتيك توك بشكل مكثف ومحاولة تقليد الترندات والمشاهير والإنغماس في أخبارهم… بعد مرور بعض الوقت تجد أنك امام فتاة لا تدري أي شئ عن كونها فتاة غير جسدها وجمالها حتي هذا يصل بشكل خاطئي.\n\n\nالإستغراق السياسي والمجاريات\nيكثر فخ الجاذبية هنا في الإستغراف السياسي لك كأب وتقصيرك في تربية أولادك او زيادة دخلك و سد رمق بيتك!"
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#أين-المشكلة",
    "href": "blog/posts/life_style/fake_graviety.html#أين-المشكلة",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "أين المشكلة؟",
    "text": "أين المشكلة؟\nالمشكلة ليست في الأنجذاب لشئ فهذا مستحيل حدوثه لكن المشكلة هل أنا فعلا أسير في المدار الصحيح الذي يتفق مع الغاية الكبري بأفضل شكل ممكن وهل توجد محاولة التحسين المستمر أم أنك تتركها للظروف وتلعب دور المفعول به! هل فعلا بعد ذهاب العمر هل هذا هو ما كنت تود أنك أمضيت فيه عمرك! الخطر يكمن أن هذا كله يحدث من شد وجذب بدون أن تتدرك في أي فضاء صار قمرك."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#جاذبية-الحياة-علي-الأرض",
    "href": "blog/posts/life_style/fake_graviety.html#جاذبية-الحياة-علي-الأرض",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "جاذبية الحياة علي الأرض",
    "text": "جاذبية الحياة علي الأرض\nطعام الروح : كما أن الجسد له غذاءة فالجسد خلق من طين تجد أن روحك تثقل وتزداد جاذبية الدنيا وشهواتها لك و كذلك فروحك لها غذاء وهو الذكر فالذكر غذاء روحك كلما أكثرت منه ارتفعت روحك الي الأعلي وخفة جاذبية الأرض لك.\nالهدف الحقيقي: الهدف أن تدور في المدار الحقيقي والأمن ولا تغريك الممرات القصيرة السريعة التي تنحرف بك ييمين وييسار الهدف أن يكون سيرك الي المولي عزوجل وذلك لن يتم الإ بمعرفة ما يجذبك ويعبدك عن المسار وتجديد النية الدائم والتوجهة الي ربك. أحب ان اسميه إستعادة المركز وتعديل البوصلة و أكثر مكان أجد نفسه فيه هو إما في صلاة صادقة في جوف الليل مع دعاء مبتهل أو في صلاة جماعة مبكرة هادئة. في تلك الحظة تجد السكينة في قلبك وتهدئ كل العواصف. اللهم أعنا علي ذكرك وشكرك وطاعتك وحسن عبادتك."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#مغدارة-المدار",
    "href": "blog/posts/life_style/fake_graviety.html#مغدارة-المدار",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "مغدارة المدار",
    "text": "مغدارة المدار\nبعض الحلول التي مازالت محل البحث والتجربة.\n\nسل نفسك ماهو المحرك الحقيقي لهذا الفعل او المهمة الحالية وبأي نية أفعلها\nماهي المشاعر المحركة لهذا العمل ومن هو مصدرها هل هم الأهل أم فتاة أم كلمة قالها احد ما ونسي ما قال!\nهل تستحق كل هذا الوقت والمجهود فهذا الرصيد من عمري الذي لا يعوض!\nهل هي حقا تقع في باب أهم الأشياء التي يجب ان افعلها ام هي شواغل تعترض الطريق\nمتابعة الوقت بفعالية من التطبيقات المقترحة لهذا :\n\nActionDash\nActivityWatch\nFocus Todo\n\n\nمقولة مميزة من “د/عبد الرحمن المسيري”\n\nوفي الرياض تفرغت تماما للموسوعة ..، وكنت أحرر بابا أسبوعيا بعنوان “إسرائيليات معاصرة” في جريدة الرياض، ولكني لاحظت أن انشغالي بالحدث اليومي بدأ يقوض من رؤيتي البانورامية الموسوعية، التي تركز علي الثوابت، والتي تتطلب إيقاعا بطئيًا، واهتمامًا بموضوعات تاريخية وفلسفية وجوانب استراتجية ربما لا تكون لها علاقة بمشارة بالحدث اليومي، ولذا توقفت عن تحرير هذا الباب) المسيري رحلتي الفكرية صفحة 539\n\nI am thinking, then i am not here!"
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#النهاية",
    "href": "blog/posts/life_style/fake_graviety.html#النهاية",
    "title": "جاذبية مزيفة و عالم مخادع",
    "section": "النهاية",
    "text": "النهاية\nهذه هي مجرد خواطر سريعة غير منسقة وقد تبدو متفرقه لفتي تعصف به الأفكار والمشاعر في فترة شديدة التقلب فلتدعوا له ولوالديه وجزاك الله كل الخير إن أكملت القراءة 😚😚"
  },
  {
    "objectID": "blog/posts/seo/the_curse_of_seo.html",
    "href": "blog/posts/seo/the_curse_of_seo.html",
    "title": "The curse of SEO",
    "section": "",
    "text": "Definition: SEO is optimizing your website pages to appear in the top results of search engines like Google and Bing.\n\nWhy is this important? It makes you visible to more people who are interested in what you provide—products, services, news, etc.\nEnough of the basics. I assume you already know what SEO is about. Now, let’s explore a darker side of being involved in SEO.\n\nHow to Track Your Changes\n\nSince SEO revolves around ranking, how do you track your position?\nThere are multiple tools I enjoy using, such as:\n\nI love to manually search keywords and track their ranks myself! :)\n\nI do this often when I need a break at the gym or during study breaks.\n\nSEMrush\n\nI use it to check domain authority, organic keywords, and traffic increase.\nSeeing green in increased Ref. Domains and Authority Score brings joy.\nI don’t use it for anything else! :)\n\nRanking Math\n\nSay hi to the overrated WordPress SEO plugin “Ranking Math SEO”\nIt claims to simplify content optimization with built-in suggestions based on widely-accepted practices.\nI use Rankmath Pro on a website I manage, showing impressions, total keywords, average position, and clicks. GSC offers all this for free!\nThis post isn’t about Rankmath; that’s for another time. In short:\n\nAI tools\nAMP\nAnalysis from Google Analytics\nInstant indexing\nBacklinks count\nLocal SEO\nNews sitemap\nPodcasts\nSchema\nSEO analysis\nSitemap\nVideo Sitemap\nWooCommerce\nGoogle Web Stories\n\nNone of these significantly impact SEO and ranking; there are other effective methods.\nWhat matters most to me with Rankmath is:\n\nTop 5 performing posts\nOther keywords\n\nI mainly use Rankmath for its focus keyword section in each article.\n\nMangools\n\nMy preferred tool! Its UI/UX is excellent, and it’s fast and efficient unlike other tools.\nWith the free account, I get:\n\n5 keyword researches daily\n8 SERP checks\n1,000 backlink analyses\nDomain profile checks for 2 domains daily\n\nFor Arabic, its keyword ideas aren’t as good.\n\nGoogle Search Console\n\nA free tool by Google offering most SEO tools’ functionalities for free and accurately.\nYou get:\n\nPerformance of your website for any keyword at any time in any region!\nPage indexing status\nBacklink analysis\nPage experience and more\n\nYou might notice a recurring theme:\n\nCharts\nChanging numbers everywhere, numbers galore!\n\n\nNeil Patel\n\nRank tracking\nSEO opportunities\nSite audit\nKeyword research\nTraffic estimation\nBacklinks\n\nKeyword Tool\n\nFor Arabic, it provides the most related suggested keywords, though many aren’t quite relevant.\n\nGuinRank\n\nNew and more tailored for Arabic, gaining power.\nI use its content and keyword tools for Arabic, providing helpful recommendations and statistics for choosing useful keywords.\n\nMoz\n\nThey even blocked my IP -__-\n\n\n\nStarting to Lose!\n\nWhat’s going wrong? I hate losing after investing time, money, and mental health into something. If you’re like me, SEO can be crushing.\n“SEO is like gambling” ~ Kareem\n\n\n\n\n\nHow to recover form SEO addiction\n\n\n\nLosing Backlinks\n\nSpam backlinks (like Khamsat, Fiverr, and Upwork)—most are harmful.\nPBN Network\n\nThis service claims safe PBNs for backlinks from Web 2.0 blogs, profiles, social bookmarking, social likes/shares, etc. I tried it, and none appeared in GSC after 3 months; worse, my site’s rank dropped.\n\nManually Added Backlinks\n\nThis package offers 70 PR10 backlinks from foreign websites, 60 Arabic guest posts, and 10 EDU backlinks, etc.\nIt worked to some extent, but the impact was minimal. Four backlinks from specific places helped more than these services.\n\nOther services are mostly spam backlinks; some guest posts might help, but aim for real backlinks spaced out from related sites.\n\nLosing Ranking\n\nThis month, a home services website I manage improved from 65th to 9th in rankings, then disappeared, and later ranked 40th, etc.\nThis cycle repeats—a page gains rank, then drops.\nIt’s stressful; don’t check daily. Weekly (or every 2-3 weeks) is less stressful and gives fairer results, focusing on what’s important.\n\nWhat’s Going Wrong?\n\nWatching page changes from these tools is like social media’s new “like” button!\nMy mind loves the green and red numbers.\nUltimately, most analyses aren’t critical. Whether 23rd or 80th, if not in the top 5, what’s the use? Daily checks yield nothing; reaching top 5 goes unnoticed until notifications and calls confirm it.\nIf SEO is your sole income source, it’s a tough job—even though it can make you a millionaire sometimes.\n\nHow to Recover\n\nHere’s what helped me recover from this addiction:\nCreate barriers for easy access:\n\nSeparate Google accounts/tabs into another browser profile. Using Brave or Bing makes this easy.\nRemove bookmarked tabs for these tools and clear browsing history.\nUse extensions to block these sites; Chrome Store has many offering motivational quotes.\n\nDelete Chrome and YouTube from mobile using ADB.\nMove tool emails to spam except weekly updates from Mangools and GSC.\n\n\n\n\n\ndark side of seo\n\n\n\nFinal Thoughts!\n\nAs a programmer, I initially thought a fast website and quality content were key in SEO. I later learned that choosing keywords and acquiring backlinks are crucial.\nA nice Arabic book which will give you true information about SEO دليلك إلي تحسين محركات البحث\nFeel free to DM on Linkedin\nUltimately, backlinks boil down to how many you buy and from whom.\nمنصة صناعة المحتوي العربي"
  },
  {
    "objectID": "blog/feed.html",
    "href": "blog/feed.html",
    "title": "Kareem’s Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nThe curse of SEO\n\n\n\n\n\n\nblogging\n\n\nseo\n\n\n\nDiscover the hidden challenges of SEO, effective tools, and strategies to track changes and recover from setbacks, while navigating the complexities of search engine optimization.\n\n\n\n\n\nJul 31, 2024\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nجاذبية مزيفة و عالم مخادع\n\n\n\n\n\n\nblogging\n\n\nidea_Forge\n\n\npublish\n\n\nrough_thoughts\n\n\nlife_style\n\n\n\nمخاوف عن الوقوع في جاذبية الأخرين وأهوائهم والابتعاد الغير مقصود عن الهدف الرئيسي وضياع البوصلة الأساسية.\n\n\n\n\n\nJul 10, 2024\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nMy little Dragon “kobo”\n\n\n\n\n\nA review about my MSI Gaming Laptop as a machine learning student and also a web developer! and want to say thanks for this amazing friend who leaved with me for 4 years.\n\n\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAfter one year of using Huawei Mate 11 without google services\n\n\n\n\n\nSharing my experience with using Huawei Mate product line for one year without huawei services, a detailed student review. describe my experience with, noteshelf,concepts, infinte painter, Flexcil and Gbox\n\n\n\n\n\nDec 7, 2023\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nHuawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!\n\n\n\n\n\nReview of the Huawei Freebuds 5i after 2 months of use. Huawei Freebuds is latest pair of noise-cancelling earbuds and share a lot in common with their stablemates the FreeBuds pro 2\n\n\n\n\n\nDec 6, 2023\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nMTEB Massive Text Embedding Benchmark\n\n\n\n\n\nMTEB Benchmark aims to provide clarity on how models perform on a variety of embedding tasks and thus serves as the gateway to finding universal text embedding applicable to a variety of tasks.\n\n\n\n\n\nOct 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntiny-gte “Tiny, yet powerful, it is small in size but packs a lot of power.”\n\n\n\n\n\nlet’s explore this applications with txtai and other workflow with some notes and future directions\n\n\n\n\n\nOct 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHow I am using NLP to improve my Websites SEO\n\n\n\n\n\n\nlife\n\n\nblogging\n\n\npublish\n\n\nseo\n\n\n\nHow i use python scripts and natural language processing to improve my landing page SEO\n\n\n\n\n\nJul 18, 2023\n\n\nKareem Elkhateb\n\n\n\n\n\n\n\n\n\n\n\n\nwhy i am blogging\n\n\n\n\n\n\nlife\n\n\nblogging\n\n\npublish\n\n\n\nwhy i am blogging and should you also blog? Why you (yes, you) should blog blogging with astro js as a machine learning engineer\n\n\n\n\n\nJul 18, 2023\n\n\nKareem Elkhateb\n\n\n\n\n\n\n\n\n\n\n\n\nhavrard CS197 AI research experiences\n\n\n\n\n\nEmbark on a transformative journey into the world of scientific research, particularly deep learning, with our comprehensive 21-lecture course. Delve into a wealth of experiences and crucial insights delivered through quick, digestible lectures, designed for enthusiasts and beginners alike. Complete the course in just one or two days, exploring topics ranging from AI language models to advanced techniques in research paper analysis.\n\n\n\n\n\nJul 18, 2023\n\n\nkareem\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "kareem's Blog",
    "section": "",
    "text": "This blog is where i struggle to learn about programming, deep learning and AGI.\nCurrently I’m Learning NLP, Generative AI and 3D vision to build charming language models that able to talk, hear and see, made me some coffee"
  },
  {
    "objectID": "index.html#get-in-touch",
    "href": "index.html#get-in-touch",
    "title": "kareem's Blog",
    "section": "💼 Get In Touch",
    "text": "💼 Get In Touch\nDo you need help operationalizing ML, Recommendition systems or large language models?\nI’m open to consulting work and other forms of advisory. Email me at kareem01095134688@gmail.com if you’d like to chat!"
  },
  {
    "objectID": "index.html#feed",
    "href": "index.html#feed",
    "title": "kareem's Blog",
    "section": "📮 Feed",
    "text": "📮 Feed\nA curated collection of blog posts and shorter form notes.\n\n\n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\n7/31/24\n\n\nThe curse of SEO\n\n\n\n\n7/10/24\n\n\nجاذبية مزيفة و عالم مخادع\n\n\n\n\n1/1/24\n\n\nMy little Dragon “kobo”\n\n\n\n\n12/7/23\n\n\nAfter one year of using Huawei Mate 11 without google services\n\n\n\n\n12/6/23\n\n\nHuawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!\n\n\n\n\n10/28/23\n\n\nMTEB Massive Text Embedding Benchmark\n\n\n\n\n10/21/23\n\n\ntiny-gte “Tiny, yet powerful, it is small in size but packs a lot of power.”\n\n\n\n\n7/18/23\n\n\nHow I am using NLP to improve my Websites SEO\n\n\n\n\n7/18/23\n\n\nwhy i am blogging\n\n\n\n\n7/18/23\n\n\nhavrard CS197 AI research experiences\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#subscribe",
    "href": "index.html#subscribe",
    "title": "kareem's Blog",
    "section": "📬 Subscribe",
    "text": "📬 Subscribe\nSubscribe via  RSS."
  },
  {
    "objectID": "notes/web-scraping/transcribe-diarize.html",
    "href": "notes/web-scraping/transcribe-diarize.html",
    "title": "Transcribe & Diarize Videos",
    "section": "",
    "text": "I wanted to generate transcriptions of videos with speaker labels. Segmenting or labeling the speakers in audio like this is referred to as Diarization or Diarisation (wikipedia). Unfortunately, OpenAi’s Whisper doesn’t do diarization.",
    "crumbs": [
      "Web Scraping",
      "Transcribe & Diarize Videos"
    ]
  },
  {
    "objectID": "notes/web-scraping/transcribe-diarize.html#download-the-audio-file-with-yt-dlp.",
    "href": "notes/web-scraping/transcribe-diarize.html#download-the-audio-file-with-yt-dlp.",
    "title": "Transcribe & Diarize Videos",
    "section": "1. Download the audio file with yt-dlp.",
    "text": "1. Download the audio file with yt-dlp.\nThe -o \"audio.%(ext)s\" argument is used to name the output as audo.mp3. The %(ext)s is a placeholder for the file extension. The --extract-audio and --audio-format mp3 arguments are used to extract the audio from the video and convert it to mp3 format.\nyt-dlp --extract-audio --audio-format mp3 \\\n    -o \"audio.%(ext)s\" https://youtu.be/g_6nQBsE4pU\nThe above command will generate audio.mp3 in the current directory.",
    "crumbs": [
      "Web Scraping",
      "Transcribe & Diarize Videos"
    ]
  },
  {
    "objectID": "notes/web-scraping/transcribe-diarize.html#generate-the-transcript-with-diarization.",
    "href": "notes/web-scraping/transcribe-diarize.html#generate-the-transcript-with-diarization.",
    "title": "Transcribe & Diarize Videos",
    "section": "2. Generate the transcript with diarization.",
    "text": "2. Generate the transcript with diarization.\nThis is done with WhisperX. Make sure you carefully follow the instructions in the WhisperX repo corresponding to Speaker Diarization: you have to click on three Hugging Face repos and accept their terms & conditions.\nThe video I’m working with has 2 speakers, so that’s why I’m setting --min_speakers and --max_speakers equal to 2. The --hf_token argument is the Hugging Face token you get from following the instructions in the WhisperX repo.\nwhisperx audio.mp3 --model large-v2 --diarize \\\n    --min_speakers 2 --max_speakers 2 --hf_token &lt;your_hf_token&gt;\nThis will produce files with the following extensions audio.{srt, vtt, txt, tsv, json} in the current directory. You can limit the formats with --output_format and write these files to a different directory with --output_dir. The .json file contains the most detailed information about the diarization, with world-level predictions, whereas the .vtt and .srt files will contain a more human-readable transcript with speaker labels. I suggest looking at these files to see which one suits your needs.\nIf looking at the .json file, I recommend using jq with a command like this to see the first row of the segments array in that file:\njq '.segments[0]' audio.json",
    "crumbs": [
      "Web Scraping",
      "Transcribe & Diarize Videos"
    ]
  },
  {
    "objectID": "notes/web-scraping/browser-to-python.html",
    "href": "notes/web-scraping/browser-to-python.html",
    "title": "Browser requests to code",
    "section": "",
    "text": "I learned this from Zachary Blackwood’s 2022 NormConf Talk.",
    "crumbs": [
      "Web Scraping",
      "Browser requests to code"
    ]
  },
  {
    "objectID": "notes/web-scraping/browser-to-python.html#example-get-a-list-of-subway-restaurants-with-python",
    "href": "notes/web-scraping/browser-to-python.html#example-get-a-list-of-subway-restaurants-with-python",
    "title": "Browser requests to code",
    "section": "Example: Get A List of Subway Restaurants With Python",
    "text": "Example: Get A List of Subway Restaurants With Python\n\nGo to https://www.subway.com/en-US/locator in Google Chrome\n\n\n\nOpen developer tools using Option + CMD + I\nGo the the network tab, and hit the clear button\n\n\n\nType in a zipcode and search. Look for a network request that seems like it is getting data, in this case GetLocations.ashx... looks super promising.\n\n\n\nRight click on that particular event and select Copy -&gt; Copy as Curl\n\n\n\nGo to curlconverter.com and paste the curl command there.\n\n\nEnjoy your python code that uses this otherwise undocumented API :)",
    "crumbs": [
      "Web Scraping",
      "Browser requests to code"
    ]
  },
  {
    "objectID": "notes/web-scraping/browser-to-python.html#bonus-parse-the-response",
    "href": "notes/web-scraping/browser-to-python.html#bonus-parse-the-response",
    "title": "Browser requests to code",
    "section": "Bonus: Parse The Response",
    "text": "Bonus: Parse The Response\nYou can parse the response data in a hacky way.\n\n# run the code from curlconverter.com, which will give you a `response` object.\n\n&gt;&gt;&gt; import json\n... response_string = response.text\n... json_string = response_string[response_string.index(\"(\") +1:response_string.index('\"AdditionalData\":')-1]+'}'\n... parsed_string = json.loads(json_string)\n... stores = parsed_string['ResultData']\n\n&gt;&gt;&gt; stores\n[{'LocationId': {'StoreNumber': 21809, 'SatelliteNumber': 0},\n  'Address': {'Address1': '4888 NW Bethany Blvd',\n   'Address2': 'Suite K-1',\n   'Address3': 'Bethany Village Centre',\n   'City': 'Portland',\n   'StateProvCode': 'OR',\n   'PostalCode': '97229',\n   'CountryCode': 'US',\n   'CountryCode3': 'USA'},\n  'Geo': {'Latitude': 45.5548,\n   'Longitude': -122.8358,\n   'TimeZoneId': 'America/Los_Angeles',\n   'CurrentUtcOffset': 0},\n  'ListingNumber': 1,\n  'OrderingUrl': 'http://order.subway.com/Stores/Redirect.aspx?s=21809&sa=0&f=r&scc=US&spc=OR',\n  'CateringUrl': 'https://www.ezcater.com/catering/pvt/subway-portland-nw-bethany-blvd',\n  'ExtendedProperties': None},\n...",
    "crumbs": [
      "Web Scraping",
      "Browser requests to code"
    ]
  },
  {
    "objectID": "notes/web-scraping/browser-to-python.html#when-to-use-this-approach",
    "href": "notes/web-scraping/browser-to-python.html#when-to-use-this-approach",
    "title": "Browser requests to code",
    "section": "When to use this approach",
    "text": "When to use this approach\nThis is great for adhoc things, but you probably want to use a headless browser and actually scrape the HTML if you want to do this in a repeatable way. But many times you want to do a one-off scrape, this isn’t so bad!",
    "crumbs": [
      "Web Scraping",
      "Browser requests to code"
    ]
  },
  {
    "objectID": "notes/how-to-learn/index.html",
    "href": "notes/how-to-learn/index.html",
    "title": "How to learn",
    "section": "",
    "text": "I read the book Mindshift and it was unituitively so good that I decided to take this class. As a parent, I learned a bunch of things that I think will be beneficial to my children’s education.\nNotes from class Learning how to learn. These notes are for me and may not make sense for others.",
    "crumbs": [
      "How to learn"
    ]
  },
  {
    "objectID": "notes/how-to-learn/index.html#focused-vs-diffused-mode",
    "href": "notes/how-to-learn/index.html#focused-vs-diffused-mode",
    "title": "How to learn",
    "section": "Focused vs Diffused Mode",
    "text": "Focused vs Diffused Mode\nYou can not access focus and diffused mode simultaneously.\nPeople have tried to access diffuse mode of thinking by bringing themselves to the point of sleep and waking up just as they fall asleep. For example, Salvador Dali - holding keys in your hand, and let the sound of keys falling the ground wake you up.\nExercise, going for a walk good way to access diffuse thinking. You must take notes right away b/c diffuse thoughts may evaporate very fast.",
    "crumbs": [
      "How to learn"
    ]
  },
  {
    "objectID": "notes/how-to-learn/index.html#procrastination-memory-and-sleep",
    "href": "notes/how-to-learn/index.html#procrastination-memory-and-sleep",
    "title": "How to learn",
    "section": "Procrastination Memory and Sleep",
    "text": "Procrastination Memory and Sleep\nThey advocate the Pomodoro technique to combating procrastination. Its like HITT.\nPeriodic relaxation (every ~ 30 minutes) is important for accessing your diffuse mode. “Its important for the mortar to dry”.\nSpaced repetition (like Anki) is important for building memory. i\nGo over what you want to learn about right before you go to sleep, this will substantially improve the chances you will dream about it and form new connections about the subject.\nExercise can help create new neurons in your hippocampus (new neurons can be created there in adulthood) and help them survive longer.",
    "crumbs": [
      "How to learn"
    ]
  },
  {
    "objectID": "notes/how-to-learn/index.html#writing-tips-diffuse-mode",
    "href": "notes/how-to-learn/index.html#writing-tips-diffuse-mode",
    "title": "How to learn",
    "section": "Writing Tips Diffuse Mode",
    "text": "Writing Tips Diffuse Mode\nDiffuse mode is very important for writing. Editing is like focus mode and creating ideas is diffuse mode. Some rules of thumb: - Do not outline, make a mind map - Do not edit while you are writing (this is really hard to do -&gt; turn off monitor and just write).https://writeordie.com - app that forces you to stay in diffuse mode. You really cannot look at the screen. - Repeating again, do not look at screen while you are writing! Only when editing.",
    "crumbs": [
      "How to learn"
    ]
  },
  {
    "objectID": "notes/how-to-learn/index.html#chunking",
    "href": "notes/how-to-learn/index.html#chunking",
    "title": "How to learn",
    "section": "Chunking",
    "text": "Chunking\n“Tying your shoes”. Best chunks are subconscious. Spoken language is the best example of chunking. You have to practice to build chunks, you cannot just observe. You have to perform the task yourself.\nYou should scan a chapter before you read it: section headings, pictures, etc. This can help you build chunks.",
    "crumbs": [
      "How to learn"
    ]
  },
  {
    "objectID": "notes/how-to-learn/index.html#illusions-of-competence",
    "href": "notes/how-to-learn/index.html#illusions-of-competence",
    "title": "How to learn",
    "section": "Illusions of competence",
    "text": "Illusions of competence\nRight after you read something, look away and repeat to yourself what you recall. You can also draw a concept map. The recall process actually improves memory.\nRecall is better than re-reading. Re-reading is effective when you let time pass so you get spaced repetition. You need to test yourself to make sure you are competent. Recall is a form of testing.\nRecall outside your place of study to strengthen your memory. This is because you can get queues from where you are studying.",
    "crumbs": [
      "How to learn"
    ]
  },
  {
    "objectID": "notes/how-to-learn/index.html#deliberate-practice",
    "href": "notes/how-to-learn/index.html#deliberate-practice",
    "title": "How to learn",
    "section": "Deliberate Practice",
    "text": "Deliberate Practice\nFocus on the bits that you find difficult. Interleaving is important, meaning learning different subjects or even sections within one subject at once. Thomas S. Khun discovered that two types of people tend to make scientific breakthroughs: (1) young people (2) those who are trained in another discipline.",
    "crumbs": [
      "How to learn"
    ]
  },
  {
    "objectID": "notes/how-to-learn/index.html#procrastination-and-memory",
    "href": "notes/how-to-learn/index.html#procrastination-and-memory",
    "title": "How to learn",
    "section": "Procrastination and Memory",
    "text": "Procrastination and Memory\nYou have already learned about the Pomodoro technique. There are other techniques.\nFocus on the process, not the product. Don’t focus on completing the homework, focus on the process that leads you to complete the homework. Process is the small chunks of time to chip away at the task. This is the idea behind the Pomodoro. Your only goal is to finish the Pomodoro, for example.",
    "crumbs": [
      "How to learn"
    ]
  },
  {
    "objectID": "notes/how-to-learn/index.html#juggling-life-and-learning",
    "href": "notes/how-to-learn/index.html#juggling-life-and-learning",
    "title": "How to learn",
    "section": "Juggling Life and Learning",
    "text": "Juggling Life and Learning\nYou should make to-do list the night before for the next day and write it down. This will allow your subconscious to work on how it will conquer that task. Furthermore, writing it down will allow you to free it from working memory.\nPlan your quitting time is important.",
    "crumbs": [
      "How to learn"
    ]
  },
  {
    "objectID": "notes/video_editing.html",
    "href": "notes/video_editing.html",
    "title": "Video Editing",
    "section": "",
    "text": "Youtube Tutorial: https://www.youtube.com/watch?v=yh77878QDVE His playlist: https://www.youtube.com/playlist?list=PLL6tMzF36ox2c–SNKiifuP8kEFh80wPu\nCMD + B -&gt; “Blade” CMD + SHIFT + [ or ] to cut to location\n\n\n\nHere is a circular camera filter with OBS, which might be easier than DVR.\nYou can crop like this\n\n\n\nYou can add pause recording as a hotkey in OBS",
    "crumbs": [
      "Video Editing"
    ]
  },
  {
    "objectID": "notes/video_editing.html#davinci-resolve",
    "href": "notes/video_editing.html#davinci-resolve",
    "title": "Video Editing",
    "section": "",
    "text": "Youtube Tutorial: https://www.youtube.com/watch?v=yh77878QDVE His playlist: https://www.youtube.com/playlist?list=PLL6tMzF36ox2c–SNKiifuP8kEFh80wPu\nCMD + B -&gt; “Blade” CMD + SHIFT + [ or ] to cut to location\n\n\n\nHere is a circular camera filter with OBS, which might be easier than DVR.\nYou can crop like this\n\n\n\nYou can add pause recording as a hotkey in OBS",
    "crumbs": [
      "Video Editing"
    ]
  },
  {
    "objectID": "notes/video_editing.html#other-tools-to-look-into",
    "href": "notes/video_editing.html#other-tools-to-look-into",
    "title": "Video Editing",
    "section": "Other tools to look into",
    "text": "Other tools to look into\n\nDescript\nRunwayML\ncapcut - from Rajeev\nAdobe Premiere\nFrame - Video collaboration that you use for Upwork etc\nEpidemic Sound - Sound by mood (Sanyam)\nCayla - Artlist\nCayla - Premium Beat\n\nCayla recommmends 1080p / 24 FPS for Youtube",
    "crumbs": [
      "Video Editing"
    ]
  },
  {
    "objectID": "publish.html",
    "href": "publish.html",
    "title": "📚 Books",
    "section": "",
    "text": "Still cooking …"
  },
  {
    "objectID": "publish.html#still-under-review",
    "href": "publish.html#still-under-review",
    "title": "📚 Books",
    "section": "",
    "text": "Still cooking …"
  },
  {
    "objectID": "papers.html",
    "href": "papers.html",
    "title": "📝 Papers",
    "section": "",
    "text": "These are a list of papers I’ve given:\n\nExplainable Artificial Intelligence of Multi-Level Stacking Ensemble for Detection of Alzheimer’s Disease Based on Particle Swarm Optimization and the Sub-Scores of Cognitive Biomarkers"
  },
  {
    "objectID": "blog/posts/seo/how_i_use_nlp_for_seo.html",
    "href": "blog/posts/seo/how_i_use_nlp_for_seo.html",
    "title": "How I am using NLP to improve my Websites SEO",
    "section": "",
    "text": "Unlocking SEO Potential with NLP: A Journey of Website Optimization\nIn the vast digital landscape, the visibility of a website amidst the sea of search results can make or break its success. Search Engine Optimization (SEO) stands as the beacon guiding businesses towards the shores of higher visibility and traffic. As the digital realm evolves, so do the strategies employed to enhance SEO. One such frontier that holds immense promise is the integration of Natural Language Processing (NLP) into SEO practices.\n\nUnderstanding the Landscape\nSEO isn’t just about optimizing keywords anymore; it’s about understanding user intent, predicting trends, and delivering value-rich content. Harnessing the power of NLP, we embark on a journey to revolutionize SEO practices for our websites. Here’s how we’re leveraging NLP to bolster our SEO efforts:\n\n\n1. Daily Downloads and Keyword Integration\nWe kickstart our journey by integrating Google Search Console into our workflow. By fetching daily downloads of our top queries, we gain invaluable insights into user behavior and preferences. These queries are seamlessly integrated into a specific folder, forming the backbone of our content optimization strategy.\n\n\n2. Content Analysis and Optimization\nNLP comes into play as we meticulously analyze our content to ensure alignment with the top queries identified. By leveraging NLP techniques, we ascertain the presence of these keywords within our content, ensuring relevance and resonance with our audience’s search intent.\n\n\n3. Predictive Analytics and Trend Spotting\nPowered by NLP, we delve into the realm of predictive analytics to forecast future trends. By analyzing historical data and current patterns, we identify emerging trends and capitalize on them proactively. This enables us to stay ahead of the curve and position our content strategically to meet evolving user demands.\n\n\n4. Semantic and Exact Match Integration\nNLP empowers us to delve deeper into the semantics of language, enabling us to differentiate between exact matches and similar meanings. Through advanced NLP algorithms, we ensure that our content not only features exact keyword matches but also resonates with synonymous terms, enhancing its visibility across diverse search queries.\n\n\nLeveling Up the Game\nAs we progress on our journey of NLP-driven SEO optimization, we outline a roadmap for leveling up our capabilities:\n\nLevel 1:\n\nData Management: Implementing robust data storage solutions tailored to multiple websites.\nVisualization: Crafting compelling visualizations using tools like Bokeh and Plotly.\nMachine Learning Models: Developing forecasting models to predict future trends.\nSemantic Search: Leveraging vector databases for semantic and exact search capabilities.\n\n\n\nLevel 2:\n\nOptimization: Streamlining our codebase through asynchronous processing and caching mechanisms.\n\n\n\nLevel 3:\n\nProduct Development: Exploring avenues to transform our NLP-driven SEO framework into software products like WordPress plugins or desktop applications.\n\n\n\nLevel 4:\n\nInnovation: Drawing inspiration from industry leaders to create bespoke solutions, such as an Arabic version of our SEO platform akin to UberSuggest and Guni Rank.\n\n\n\n\nConclusion\nI mainly using NLP with python to improve my landing pages for home services like the following services: Here are the markdown links with target titles for the provided text:\n\nشركة عزل فوم بالمدينة المنورة\nشركة عزل فوم بمكة\nشركة عزل فوم بالطائف\nشركة عزل اسطح بالاحساء\nشركة عزل اسطح بالدمام\nمنصة صناعة المحتوي العربي\n\nIn the ever-evolving landscape of SEO, the integration of NLP marks a paradigm shift towards more sophisticated and nuanced optimization strategies. By harnessing the power of NLP, we not only decipher the language of search but also anticipate and cater to the evolving needs of our audience. As we continue to refine our approach and explore new frontiers, the synergy between NLP and SEO promises to redefine the digital landscape, empowering businesses to thrive in an era of unparalleled connectivity and discovery. you can read more articles here"
  },
  {
    "objectID": "blog/posts/life_style/why_I_am_blogging.html#why-i-am-blogging",
    "href": "blog/posts/life_style/why_I_am_blogging.html#why-i-am-blogging",
    "title": "why i am blogging",
    "section": "Why I am blogging",
    "text": "Why I am blogging\n\nI am blogging to establish a presence on the internet and hope to collaborate with people who are interested in what I write or think about (reducing the search space by reversing the process).\nIt serves as a resume and blueprint for my existence in this world.\nMy goal is to help others by providing valuable content that makes their lives easier and better.\nOrganizing my knowledge and recapping topics I’ve forgotten helps me experience “aha” moments! 💡\n\nIt’s a test of whether I truly understand something or not.\n\nI don’t like social media posts, Facebook, Twitter, or LinkedIn articles. I believe these platforms are not the best places for technical blogs, and their disadvantages outweigh the advantages.\nI value the freedom of speech. Some topics or thoughts may be censored on social media, but I want to express my opinions without restrictions from others whose opinions I may not respect.\nI want to discuss topics while I’m learning them because they’re still fresh in my mind. This will help anyone in a similar position as me in the future.\nWhen studying a topic and knowing that I can write about it on my blog, I find my mind more focused on details that would fit well in the blog. This makes the learning process more enjoyable, focused, and valuable.\nI want my posts and knowledge to be more organized!\n\nWho will search for a post written six years ago on Facebook or see your first tweet?\nThis problem is related to the feed of these social platforms."
  },
  {
    "objectID": "blog/posts/life_style/why_I_am_blogging.html#references",
    "href": "blog/posts/life_style/why_I_am_blogging.html#references",
    "title": "why i am blogging",
    "section": "References",
    "text": "References\n\nhttps://medium.com/@racheltho/why-you-yes-you-should-blog-7d2544ac1045"
  },
  {
    "objectID": "blog/posts/courses/havrard CS197 AI research experiences.html",
    "href": "blog/posts/courses/havrard CS197 AI research experiences.html",
    "title": "havrard CS197 AI research experiences",
    "section": "",
    "text": "This course consists of 21 quick lectures that include valuable experiences and important tips for anyone interested in the field of scientific research, especially deep learning. The course can be completed in approximately one or two days. The title is not very precise, and the content of the lectures ranges from about 8 to 26 pages each. Some topics may not be directly related to the specifics of scientific research, but they are generally very helpful lectures for beginners in the field."
  },
  {
    "objectID": "blog/posts/courses/havrard CS197 AI research experiences.html#table-of-contents",
    "href": "blog/posts/courses/havrard CS197 AI research experiences.html#table-of-contents",
    "title": "havrard CS197 AI research experiences",
    "section": "",
    "text": "This course consists of 21 quick lectures that include valuable experiences and important tips for anyone interested in the field of scientific research, especially deep learning. The course can be completed in approximately one or two days. The title is not very precise, and the content of the lectures ranges from about 8 to 26 pages each. Some topics may not be directly related to the specifics of scientific research, but they are generally very helpful lectures for beginners in the field."
  },
  {
    "objectID": "blog/posts/courses/havrard CS197 AI research experiences.html#reviews",
    "href": "blog/posts/courses/havrard CS197 AI research experiences.html#reviews",
    "title": "havrard CS197 AI research experiences",
    "section": "Reviews",
    "text": "Reviews\nLecture 1: Exciting Advances with AI Language Models Content : Interact with language models like GPT-3’s text completion and use Codex’s code generation abilities feedback : ⭐ (1/5)\n\nLecture 2: The Zen of python Content : vscode,git,conad,linting and Debugging. feedback: feedback : ⭐ (1/5)\n\nLecture 3: Reading AI Research papers Content :\n\nConduct a literature search to identify papers relevant to a topic of interest\nDifference between Reading Wide and Reading deep and how to balance between them\nHow to use Google Scholar and paper with code feedback : ⭐⭐⭐⭐⭐ (5/5)\n\n\nLecture 4: In-Tune with Jazz Hands Content:\n\nquick intro into huggingface\nTokenization\nCausal language modeling (CLM) feedback : ⭐⭐⭐⭐ (4/5)\n\n\nLecture 5: Lightning McTorch Content :\n\nFine-tuning A vision Transformer\nIntro to pytorch lightning (Lightning)\nData Loading\nHow to Build a Neural net Module with lightning and how lightning modules work feedback : ⭐⭐⭐⭐ (4/5)\n\n\nLecture 6 & 7: Moonwalking with Pytorch Content :\n\nPytorch Exercises\nTensors\nAutograd and neural networks feedback : ⭐ (1/5)\n\n\nLecture 8 & 9: Experiment Organization Spakrs Joy Content :\n\nWeight and Biases\nHyperparameter Search\nHydra feedback : ⭐⭐⭐⭐ (4/5)\n\n\nLecture 10 & 11 : I Dreamed a Dream Content\n\nIdentifying Gaps in A Research Paper\n\nCLIP and CheXzero\n\nGenerating Ideas for Building a Research Paper\nIterating on your research ideas feedback : ⭐⭐⭐⭐⭐ (5/5)\n\n\nLecture 12 & 13 : Today Was a Fairytale\n\nhow to deconstruct the elements of a research paper and their sequence\nResulting template that you can use as a general example feedback : ⭐⭐⭐⭐ (4/5)\n\n\nLecture 14 & 15: Deep Learning on Cloud Nine didn’t complete it 🙃🙃🙃\n\nLecture 16 & 17:Make your dreams come tuned Content\n\nhigh level use of Stable Diffusion using a Dreambooth template\nUse AWS to accelerate the training of Stable Diffusion models with GPUs\nHF Accelerator feedback : ⭐⭐ (2/5)\n\n\nLecture 18 : Research Productivity Power-Ups Content\n\nHow update meetings and working sessions\norganizing your efforts on a project\nwhat is technical dept and examples on it feedback : ⭐⭐⭐⭐ (4/5)\n\n\nLecture 19 :The AI Ninja Content\n\nHow to make Steady Progress\nSome Research Skills\nDiscussion Questions feedback : ⭐⭐ (2/5) I found that Colah’ blog content about research is better in the context and offers a great details\n\n\nLecture 20: Bejeweled ⭐⭐⭐⭐⭐(5/5)\n\nhow to make a slides to improve your research talk\nAssertion Evidence Approach feedback : ⭐⭐ (2/5) This is great related talk from MIT about this topic How to speak ⭐⭐⭐⭐⭐(5/5)\n\n\nLecture 21 : Model Showdown Content\n\nStatistical Testing feedback : ⭐⭐ ⭐(3/5)"
  },
  {
    "objectID": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html",
    "href": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html",
    "title": "tiny-gte “Tiny, yet powerful, it is small in size but packs a lot of power.”",
    "section": "",
    "text": "#definition : This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search. It is distilled from thenlper/gte-small, with comparable (slightly worse) performance at around half the size."
  },
  {
    "objectID": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#table-of-contents",
    "href": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#table-of-contents",
    "title": "tiny-gte “Tiny, yet powerful, it is small in size but packs a lot of power.”",
    "section": "",
    "text": "#definition : This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search. It is distilled from thenlper/gte-small, with comparable (slightly worse) performance at around half the size."
  },
  {
    "objectID": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#details",
    "href": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#details",
    "title": "tiny-gte “Tiny, yet powerful, it is small in size but packs a lot of power.”",
    "section": "Details",
    "text": "Details\n\nIt’s around ~45MB very small compared to other models like MiniLM-L6-V2 which is equal to ~80 MB\nEmbedding vector size 384d\nBERT based\nDistilied from thenlper/gte-small,"
  },
  {
    "objectID": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#notice-about-using-small-size",
    "href": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#notice-about-using-small-size",
    "title": "tiny-gte “Tiny, yet powerful, it is small in size but packs a lot of power.”",
    "section": "Notice about using small size",
    "text": "Notice about using small size"
  },
  {
    "objectID": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#use-cases",
    "href": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#use-cases",
    "title": "tiny-gte “Tiny, yet powerful, it is small in size but packs a lot of power.”",
    "section": "Use Cases",
    "text": "Use Cases"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#intro",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#intro",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "Intro",
    "text": "Intro\nHi, In this fast blog i will talk about my review with Huawei Freebuds 5i, which is the first noise-cancelling earbuds i have tried. This is not an ad or even affiliate product, it’s my own review for fun and just seeking of knowledge."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#who-am-i",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#who-am-i",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "Who am i !",
    "text": "Who am i !\n\nI am Kareem, a college student interested in machine learning and web technology.\nI enjoy working deeply and seeking out quiet places, but I live in an area with some noisy disturbances in the mornings - people walking down the street, kids playing around the house, street vendors - which often interrupt my focus and break my state of flow.\nI wish there was a solution to block out all these sounds so I could live in an isolated place free of annoying noises! Using noise-cancelling headphones or heading into outer space would be ideal environments with no bothersome sounds around."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#how-i-bought-it",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#how-i-bought-it",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "how i bought it",
    "text": "how i bought it\n\nI bought it from amazon prime, and it cost me around 100$ or 3,200 pounds. It reached within two days."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#first-impressions",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#first-impressions",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "First impressions",
    "text": "First impressions\n\nUpon unboxing and using it for the first time, I was genuinely pleased with the initial track I played.\nThe sound quality was noticeably superior compared to my phone or any other earbuds I’ve previously used. I then tested the noise-cancelling feature and was amazed when I couldn’t hear my younger brother calling me.\nThe street noises were effectively blocked out, with only a faint hum reaching my ears, which was quite tolerable. Initially, the earbud tips were a bit uncomfortable, but after switching to a smaller size, the discomfort was resolved. Everything seemed perfect, except for a slight pressure in my ears when using the noise-cancelling feature, particularly noticeable the following morning. Despite this, my ears seem to crave the earbuds and my skin seems to miss them when they’re not in use. This can be a bit of a downside, but it’s not always the case."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#is-noise-cancelling-actually-work",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#is-noise-cancelling-actually-work",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "Is noise cancelling actually work ?",
    "text": "Is noise cancelling actually work ?\nI’ve used these earbuds in various settings:\n\nSubway: The noise-cancelling feature combined with my music created an immersive experience, effectively blocking out any other sounds and allowing me to enjoy my tunes in peace.\nCollege: Amidst the chatter and shouts of other students, I was able to retreat into my own world of sound.\nBus: The noise of the bus engine was successfully blocked out, but I could still hear the conversations of those sitting next to me. It wasn’t overly bothersome, but it didn’t provide complete isolation.\n\nIn summary, the noise-cancelling feature works well, but it doesn’t provide absolute silence. I can still hear some ambient sounds. One noticeable issue is that when I make calls using the earbuds, I can hear the other person clearly, but they often complain about the clarity of my voice. They say it sounds distant and unclear, sometimes even asking to call back later. This issue is particularly prevalent when I’m on the bus."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-modes-of-the-freebuds-and",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-modes-of-the-freebuds-and",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "the modes of the Freebuds and",
    "text": "the modes of the Freebuds and\nHere is a rephrased version of the key points about the Huawei Freebuds 5i’s features:\nNoise Cancellation Modes:\n\nNoise Cancelling Mode: Actively cancels out ambient noise. Uses more battery power.\nOff Mode: No active noise cancellation, but still provides some passive noise isolation. Less battery usage.\nAwareness Mode: Allows ambient sounds to be heard clearly. Useful for hearing announcements at the gym or people talking to you. However, my own voice sounds muted in this mode, so I have to remove the earbuds temporarily to hold conversations.\n\nSound Quality Presets:\n\nDefault: No sound enhancements applied.\nTreble Boost: Boosts treble frequencies. I haven’t used this.\nBass Boost: Emphasizes bass when listening to music like hip-hop.\nVoices: Optimizes sound for speech clarity. I use this for podcasts.\n\nConnection Priority Modes:\n\nBalance Mode: Balances audio quality and connection stability.\nSound Quality Priority: Prioritizes sound quality over connectivity. Uses more power which may cause occasional lag.\n\nI have not noticed any discernible difference between these two modes, so I just use the Balance mode."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-gestures",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-gestures",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "The Gestures",
    "text": "The Gestures\nThe Huawei Freebuds 5i offer various gesture controls:\n\nDouble-tap, Triple-tap, Press & hold, Swipe\n\nI particularly enjoy the swipe gesture for volume control, as it works smoothly. The press and hold gesture is a bit slow, and the triple-tap gesture can be annoying since tapping your ear three times isn’t very comfortable.\nOccasionally, the Freebuds don’t recognize when I’ve inserted the left or right earbud, and I continue listening with just one earbud without realizing the other isn’t connected. This doesn’t happen often, though."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-compatibility-with-other-devices",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-compatibility-with-other-devices",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "The compatibility with other devices",
    "text": "The compatibility with other devices\n\nI love how it connect with both the phone and tablet without any problems or conflict\nI’ve been using the Freebuds with my Realme phone, MSI Linux laptop, and Huawei Mate Pad 11.\nThe connection with the Realme phone is seamless, regardless of whether the AI Life application is used or not.\nWhen it comes to the Huawei Mate Pad 11, there’s a feature that allows you to adjust settings directly from the Bluetooth menu. This is a functionality that isn’t available on standard Android devices without the AI Life app.\n\n\nLinux connection\nI’ve connected the Freebuds to my Linux laptop using the ‘bluetoothctl’ command. However, I’ve encountered an issue where I need to restart Bluetooth each time I want to establish a connection for it to work properly"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-case-and-overall-design",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-case-and-overall-design",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "The case and overall design",
    "text": "The case and overall design\n\nThe design of the Freebuds is truly appealing. It has a unique aesthetic that sets it apart from other earbuds, giving it a premium feel.\nIn terms of design, the FreeBuds 5i bear a resemblance to the 4i model, but they are 11% lighter and have shorter stems. They come with an IP54 rating, making them dust-tight and splash-resistant. The color options include a new “Isle Blue”, along with “Nebula Black” and “Ceramic White”. The package includes small, medium, and large silicone eartips, as well as a short USB-C cable for charging the case.\nI love the sound of closing it, it’s a loud sound but lovely :)"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-battery",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-battery",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "The battery",
    "text": "The battery\n\nThe battery is really nice; I haven’t felt that I am missing the need to recharge it or that it has gone off at any time.\n\n\nBattery capacity\n\nPer earbud: 55 mAh (min)*\nCharging case: 410 mAh (min)*\n\n\n\nPlaytime\n\nMusic playback on 1 charge: 6.0 hours (with ANC enabled)**\nMusic playback on 1 charge: 7.5 hours (with ANC disabled)**\nMusic playback with charging case: 18.5 hours (with ANC enabled)**\nMusic playback with charging case: 28 hours (with ANC disabled)**\n\n\n\nCharging Time\n\nAbout 60 minutes for the earbuds (in the charging case)***\nAbout 110 for charging case without earbuds (wired)***"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#references",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#references",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "References",
    "text": "References\n\nhttps://smarttech101.com/bluetoothctl-management-of-bluetooth-devices-in-linux/\nhttps://askubuntu.com/questions/1225896/huawei-freebuds-3-pairing-with-ubuntu-18-04"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "",
    "text": "Here is an expanded version of your blog post with some additional details:"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#table-of-contents",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#table-of-contents",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "",
    "text": "Here is an expanded version of your blog post with some additional details:"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#why-i-bought-it",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#why-i-bought-it",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "Why I bought it",
    "text": "Why I bought it\nI purchased the Huawei tablet because I enjoy creative activities like drawing, taking notes, and reading books. I wished to have an iPad or premium tablet with a good stylus to fully explore my creative potential. My brother found an excellent deal on this Huawei tablet for around 60% off retail price and gifted it to me. I’m very thankful to him!"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#pros",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#pros",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "Pros",
    "text": "Pros\n\nExcellent audio quality with quad speakers\nGorgeous 10.95-inch LCD display\n\n2560x1600 resolution\n120Hz refresh rate for smooth visuals\n\nFast charging capabilities\n\nLarge 7250 mAh battery\nSupports 22.5W fast wired charging\n\nComfortable lightweight design, easy to use for long periods\nSeamless integration with other Huawei devices like watches and earbuds\nResponsive stylus with good palm rejection"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#cons",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#cons",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "Cons",
    "text": "Cons\n\nTablet gets hot with prolonged intensive use like drawing or taking notes. Quite annoying.\nBattery life is decent but not enough to last a full day with heavy usage\nFrequent ads in App Gallery and default music app are frustrating\n\nShould not see ads just trying to open App Gallery\nDefault music app tries to push online streaming service with more ads\n\nMany apps spam notifications asking to reopen them. Very irritating."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#using-huawei-devices-with-linux",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#using-huawei-devices-with-linux",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "Using Huawei Devices with Linux",
    "text": "Using Huawei Devices with Linux\n\nFile transfers require a cable, no wireless sharing\nMust use third party apps like KDE Connect for notifications\nCan’t develop custom themes or scripts due to lack of developer tools\nSyncing to Linux with Syncthing is slow and buggy\nOverall poor integration with Linux compared to Android/Windows"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#issues-with-google-services-on-huawei",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#issues-with-google-services-on-huawei",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "Issues with Google Services on Huawei",
    "text": "Issues with Google Services on Huawei\n\nStylus Apps\n\nInfinite Painter drawing app has broken stylus support and no pressure sensitivity\nNoteShelf note taking app can’t sync properly with cloud drives\nNebo note taking app has subpar palm rejection and no Arabic language support\nFlexcil best ebook reader/annotator but lacks Google Drive integration\n\n\n\nGbox Solution\n\nProvides access to YouTube, Maps and other Google apps\nAvailable on App Gallery with native integration\nMinimal battery drain\nBut lacks support for many Google services like Podcasts\nBuggy syncing with Google Keep\nCan’t leverage Google Drive within other apps\n\n\n\nAPK Pure\n\nApps sometimes fail to open, just black screen\nToo many ads\nLacks reliability compared to Play Store\n\nOverall, while the Huawei tablet offers excellent hardware, the software experience is hampered by lack of Google services. This leads to janky third party solutions and poor integration with Linux systems. I still enjoy using the tablet but hope someday Huawei can properly resolve these issues."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#references",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#references",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "references",
    "text": "references\n\nhttps://www.noteshelf.net/\nhttps://www.gboxlab.com/\nhttps://www.infinitestudio.art/painter.php"
  }
]